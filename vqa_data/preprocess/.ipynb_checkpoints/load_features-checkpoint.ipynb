{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load pre-trained features from Faster RCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import numpy as np\n",
    "import csv\n",
    "import sys\n",
    "import zlib\n",
    "import time\n",
    "import glob\n",
    "import mmap\n",
    "import h5py\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv.field_size_limit(sys.maxsize)\n",
    "\n",
    "FIELDNAMES = [\"image_id\", \"image_w\", \"image_h\", \"num_boxes\", \"boxes\", \"features\"]\n",
    "trainval_path = \"/ceph/kien/features/adaptive/trainval/*\"\n",
    "test_path = \"/ceph/kien/features/adaptive/test2015/*\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{533452: OrderedDict([('image_id', 533452), ('image_w', 640), ('image_h', 478), ('num_boxes', 30), ('boxes', array([[  16.92600632,  207.32254028,  638.92669678,  477.20336914],\n",
      "       [ 165.13946533,    0.        ,  638.92669678,  368.23352051],\n",
      "       [ 372.32119751,    0.        ,  638.92669678,  410.76623535],\n",
      "       [ 249.10119629,  321.56967163,  451.45025635,  468.78414917],\n",
      "       [  53.49969101,   12.04119587,  370.06698608,  477.20336914],\n",
      "       [ 571.78887939,    0.        ,  629.96490479,  118.63146973],\n",
      "       [ 334.27658081,    0.        ,  476.74145508,   67.24216461],\n",
      "       [ 375.36029053,    0.        ,  405.55444336,   28.27275658],\n",
      "       [  41.51044846,   35.07247925,  237.24453735,  250.68437195],\n",
      "       [ 311.44854736,   45.9132843 ,  499.88180542,  241.3283844 ],\n",
      "       [   0.        ,    0.        ,  289.45135498,  126.67928314],\n",
      "       [   0.        ,  173.48060608,  284.55725098,  376.94607544],\n",
      "       [ 223.39830017,  186.83370972,  441.93817139,  421.12670898],\n",
      "       [ 328.87426758,   40.9957428 ,  504.01849365,  328.52746582],\n",
      "       [ 103.35150909,   84.39376068,  239.09828186,  168.70849609],\n",
      "       [ 464.1317749 ,    0.        ,  638.92669678,  351.8137207 ],\n",
      "       [ 259.24169922,  118.46354675,  310.56463623,  175.28240967],\n",
      "       [ 152.64199829,  116.58963776,  224.37762451,  157.39234924],\n",
      "       [ 187.9072113 ,  125.25714111,  384.50674438,  310.93164062],\n",
      "       [ 291.00915527,   72.68478394,  450.10641479,  318.05908203],\n",
      "       [ 616.07800293,   25.29766273,  638.92669678,  142.20831299],\n",
      "       [   0.        ,   43.2223587 ,   52.32252121,  162.87367249],\n",
      "       [  52.96515274,    0.        ,  253.19876099,  135.55471802],\n",
      "       [   1.06332445,  391.73492432,  161.51728821,  477.20336914],\n",
      "       [ 465.05181885,    0.        ,  485.26934814,   28.269207  ],\n",
      "       [ 227.34121704,  114.92823792,  422.74475098,  304.61029053],\n",
      "       [   2.79074049,    0.        ,  438.24682617,  117.42710114],\n",
      "       [ 119.19967651,  109.90029144,  148.84538269,  161.70201111],\n",
      "       [   0.        ,    0.        ,  162.20393372,  442.52560425],\n",
      "       [ 249.63920593,  299.97177124,  420.4758606 ,  417.84579468]], dtype=float32)), ('features', array([[  2.44353622e-01,   0.00000000e+00,   0.00000000e+00, ...,\n",
      "          0.00000000e+00,   2.40697227e-02,   1.39951240e-03],\n",
      "       [  3.17626111e-02,   2.67566461e-02,   0.00000000e+00, ...,\n",
      "          1.04201123e-01,   2.65151948e-01,   0.00000000e+00],\n",
      "       [  7.89645195e-01,   1.08875968e-01,   0.00000000e+00, ...,\n",
      "          8.12892094e-02,   1.05993912e-01,   2.88507253e-01],\n",
      "       ..., \n",
      "       [  1.21329660e-02,   0.00000000e+00,   3.44063179e-03, ...,\n",
      "          0.00000000e+00,   3.43813062e+00,   0.00000000e+00],\n",
      "       [  9.65857983e-01,   0.00000000e+00,   0.00000000e+00, ...,\n",
      "          1.15448209e-02,   4.29092616e-01,   0.00000000e+00],\n",
      "       [  1.00280547e+00,   0.00000000e+00,   0.00000000e+00, ...,\n",
      "          0.00000000e+00,   9.00873661e-01,   9.14227486e-01]], dtype=float32))])}\n"
     ]
    }
   ],
   "source": [
    "# Test the dataset's structure\n",
    "infile = \"/ceph/kien/features/adaptive/trainval/karpathy_val_resnet101_faster_rcnn_genome.tsv\"\n",
    "in_data = {}\n",
    "\n",
    "with open(infile) as tsv_in_file:\n",
    "    reader = csv.DictReader(tsv_in_file, delimiter=\"\\t\", fieldnames = FIELDNAMES)\n",
    "    for item in reader:\n",
    "        item[\"image_id\"] = int(item[\"image_id\"])\n",
    "        item[\"image_h\"] = int(item[\"image_h\"])\n",
    "        item[\"image_w\"] = int(item[\"image_w\"])   \n",
    "        item[\"num_boxes\"] = int(item[\"num_boxes\"])\n",
    "        for field in [\"boxes\", \"features\"]:\n",
    "            item[field] = np.frombuffer(base64.decodebytes(bytes(item[field], \"utf-8\")), \n",
    "                  dtype=np.float32).reshape((item[\"num_boxes\"],-1))\n",
    "\n",
    "        in_data[item[\"image_id\"]] = item\n",
    "        break\n",
    "print(in_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def statistic(data_path):\n",
    "    num_img = 0\n",
    "    num_feat = 0\n",
    "    files = glob.glob(data_path)\n",
    "    for file in files:\n",
    "        with open(file) as tsv_file:\n",
    "            reader = csv.DictReader(tsv_file, delimiter=\"\\t\", fieldnames = FIELDNAMES)\n",
    "            for item in reader:\n",
    "                num_img += 1\n",
    "                num_feat += int(item[\"num_boxes\"])\n",
    "    \n",
    "    return num_img, num_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trainval_num_img, trainval_num_feat = statistic(trainval_path)\n",
    "# print(trainval_num_img)\n",
    "# print(trainval_num_feat)\n",
    "\n",
    "# test_num_img, test_num_feat = statistic(test_path)\n",
    "# print(test_num_img)\n",
    "# print(test_num_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainval_num_img = 123287\n",
    "trainval_num_feat = 3924253\n",
    "test_num_img = 81434\n",
    "test_num_feat = 2566887"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_features(num_img, num_feat, data_path, data_file):\n",
    "    img_idx = {}\n",
    "    counter = 0\n",
    "    feat_counter = 0\n",
    "    \n",
    "    boxes = data_file.create_dataset(\"boxes\", (num_feat, 4), dtype=np.float32)\n",
    "    features = data_file.create_dataset(\"features\", (num_feat, 2048), dtype=np.float32)\n",
    "    img_start_idx = data_file.create_dataset(\"img_start_idx\", (num_img,), dtype=np.int64)\n",
    "    img_end_idx = data_file.create_dataset(\"img_end_idx\", (num_img,), dtype=np.int64)\n",
    "    image_h = data_file.create_dataset(\"image_h\", (num_img,), dtype=np.int64)\n",
    "    image_w = data_file.create_dataset(\"image_w\", (num_img,), dtype=np.int64)\n",
    "    \n",
    "    files = glob.glob(data_path)\n",
    "    for file in files:\n",
    "        with open(file) as tsv_file:\n",
    "            reader = csv.DictReader(tsv_file, delimiter=\"\\t\", fieldnames = FIELDNAMES)\n",
    "            for item in reader:\n",
    "                num_boxes = int(item[\"num_boxes\"])\n",
    "                image_h[counter] = int(item[\"image_h\"])\n",
    "                image_w[counter] = int(item[\"image_w\"])\n",
    "                boxes[feat_counter:feat_counter + num_boxes] = np.frombuffer(base64.decodebytes(\n",
    "                    bytes(item[\"boxes\"], \"utf-8\")), dtype=np.float32).reshape((num_boxes,-1))\n",
    "                features[feat_counter:feat_counter + num_boxes] = np.frombuffer(base64.decodebytes(\n",
    "                    bytes(item[\"features\"], \"utf-8\")), dtype=np.float32).reshape((num_boxes,-1))\n",
    "                img_start_idx[counter] = feat_counter\n",
    "                img_end_idx[counter] = feat_counter + num_boxes - 1\n",
    "                feat_counter += num_boxes\n",
    "                img_idx[int(item[\"image_id\"])] = counter\n",
    "                counter += 1\n",
    "                if counter % 1000 == 0:\n",
    "                    print(\"processing %i/%i\" % (counter, num_img))\n",
    "                    \n",
    "    return img_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainval_images_path = \"/ceph/kien/features/trainval_images.h5\"\n",
    "test_images_path = \"/ceph/kien/features/test_images.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 1000/123287\n",
      "processing 2000/123287\n",
      "processing 3000/123287\n",
      "processing 4000/123287\n",
      "processing 5000/123287\n",
      "processing 6000/123287\n",
      "processing 7000/123287\n",
      "processing 8000/123287\n",
      "processing 9000/123287\n",
      "processing 10000/123287\n",
      "processing 11000/123287\n",
      "processing 12000/123287\n",
      "processing 13000/123287\n",
      "processing 14000/123287\n",
      "processing 15000/123287\n",
      "processing 16000/123287\n",
      "processing 17000/123287\n",
      "processing 18000/123287\n",
      "processing 19000/123287\n",
      "processing 20000/123287\n",
      "processing 21000/123287\n",
      "processing 22000/123287\n",
      "processing 23000/123287\n",
      "processing 24000/123287\n",
      "processing 25000/123287\n",
      "processing 26000/123287\n",
      "processing 27000/123287\n",
      "processing 28000/123287\n",
      "processing 29000/123287\n",
      "processing 30000/123287\n",
      "processing 31000/123287\n",
      "processing 32000/123287\n",
      "processing 33000/123287\n",
      "processing 34000/123287\n",
      "processing 35000/123287\n",
      "processing 36000/123287\n",
      "processing 37000/123287\n",
      "processing 38000/123287\n",
      "processing 39000/123287\n",
      "processing 40000/123287\n",
      "processing 41000/123287\n",
      "processing 42000/123287\n",
      "processing 43000/123287\n",
      "processing 44000/123287\n",
      "processing 45000/123287\n",
      "processing 46000/123287\n",
      "processing 47000/123287\n",
      "processing 48000/123287\n",
      "processing 49000/123287\n",
      "processing 50000/123287\n",
      "processing 51000/123287\n",
      "processing 52000/123287\n",
      "processing 53000/123287\n",
      "processing 54000/123287\n",
      "processing 55000/123287\n",
      "processing 56000/123287\n",
      "processing 57000/123287\n",
      "processing 58000/123287\n",
      "processing 59000/123287\n",
      "processing 60000/123287\n",
      "processing 61000/123287\n",
      "processing 62000/123287\n",
      "processing 63000/123287\n",
      "processing 64000/123287\n",
      "processing 65000/123287\n",
      "processing 66000/123287\n",
      "processing 67000/123287\n",
      "processing 68000/123287\n",
      "processing 69000/123287\n",
      "processing 70000/123287\n",
      "processing 71000/123287\n",
      "processing 72000/123287\n",
      "processing 73000/123287\n",
      "processing 74000/123287\n",
      "processing 75000/123287\n",
      "processing 76000/123287\n",
      "processing 77000/123287\n",
      "processing 78000/123287\n",
      "processing 79000/123287\n",
      "processing 80000/123287\n",
      "processing 81000/123287\n",
      "processing 82000/123287\n",
      "processing 83000/123287\n",
      "processing 84000/123287\n",
      "processing 85000/123287\n",
      "processing 86000/123287\n",
      "processing 87000/123287\n",
      "processing 88000/123287\n",
      "processing 89000/123287\n",
      "processing 90000/123287\n",
      "processing 91000/123287\n",
      "processing 92000/123287\n",
      "processing 93000/123287\n",
      "processing 94000/123287\n",
      "processing 95000/123287\n",
      "processing 96000/123287\n",
      "processing 97000/123287\n",
      "processing 98000/123287\n",
      "processing 99000/123287\n",
      "processing 100000/123287\n",
      "processing 101000/123287\n",
      "processing 102000/123287\n",
      "processing 103000/123287\n",
      "processing 104000/123287\n",
      "processing 105000/123287\n",
      "processing 106000/123287\n",
      "processing 107000/123287\n",
      "processing 108000/123287\n",
      "processing 109000/123287\n",
      "processing 110000/123287\n",
      "processing 111000/123287\n",
      "processing 112000/123287\n",
      "processing 113000/123287\n",
      "processing 114000/123287\n",
      "processing 115000/123287\n",
      "processing 116000/123287\n",
      "processing 117000/123287\n",
      "processing 118000/123287\n",
      "processing 119000/123287\n",
      "processing 120000/123287\n",
      "processing 121000/123287\n",
      "processing 122000/123287\n",
      "processing 123000/123287\n"
     ]
    }
   ],
   "source": [
    "trainval_images = h5py.File(trainval_images_path, \"w\")\n",
    "trainval_images_idx = load_features(trainval_num_img, trainval_num_feat, trainval_path, trainval_images)\n",
    "torch.save(trainval_images_idx, \"/ceph/kien/features/trainval_images.pt\")\n",
    "trainval_images.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing 1000/81434\n",
      "processing 2000/81434\n",
      "processing 3000/81434\n",
      "processing 4000/81434\n",
      "processing 5000/81434\n",
      "processing 6000/81434\n",
      "processing 7000/81434\n",
      "processing 8000/81434\n",
      "processing 9000/81434\n",
      "processing 10000/81434\n",
      "processing 11000/81434\n",
      "processing 12000/81434\n",
      "processing 13000/81434\n",
      "processing 14000/81434\n",
      "processing 15000/81434\n",
      "processing 16000/81434\n",
      "processing 17000/81434\n",
      "processing 18000/81434\n",
      "processing 19000/81434\n",
      "processing 20000/81434\n",
      "processing 21000/81434\n",
      "processing 22000/81434\n",
      "processing 23000/81434\n",
      "processing 24000/81434\n",
      "processing 25000/81434\n",
      "processing 26000/81434\n",
      "processing 27000/81434\n",
      "processing 28000/81434\n",
      "processing 29000/81434\n",
      "processing 30000/81434\n",
      "processing 31000/81434\n",
      "processing 32000/81434\n",
      "processing 33000/81434\n",
      "processing 34000/81434\n",
      "processing 35000/81434\n",
      "processing 36000/81434\n",
      "processing 37000/81434\n",
      "processing 38000/81434\n",
      "processing 39000/81434\n",
      "processing 40000/81434\n",
      "processing 41000/81434\n",
      "processing 42000/81434\n",
      "processing 43000/81434\n",
      "processing 44000/81434\n",
      "processing 45000/81434\n",
      "processing 46000/81434\n",
      "processing 47000/81434\n",
      "processing 48000/81434\n",
      "processing 49000/81434\n",
      "processing 50000/81434\n",
      "processing 51000/81434\n",
      "processing 52000/81434\n",
      "processing 53000/81434\n",
      "processing 54000/81434\n",
      "processing 55000/81434\n",
      "processing 56000/81434\n",
      "processing 57000/81434\n",
      "processing 58000/81434\n",
      "processing 59000/81434\n",
      "processing 60000/81434\n",
      "processing 61000/81434\n",
      "processing 62000/81434\n",
      "processing 63000/81434\n",
      "processing 64000/81434\n",
      "processing 65000/81434\n",
      "processing 66000/81434\n",
      "processing 67000/81434\n",
      "processing 68000/81434\n",
      "processing 69000/81434\n",
      "processing 70000/81434\n",
      "processing 71000/81434\n",
      "processing 72000/81434\n",
      "processing 73000/81434\n",
      "processing 74000/81434\n",
      "processing 75000/81434\n",
      "processing 76000/81434\n",
      "processing 77000/81434\n",
      "processing 78000/81434\n",
      "processing 79000/81434\n",
      "processing 80000/81434\n",
      "processing 81000/81434\n"
     ]
    }
   ],
   "source": [
    "test_images = h5py.File(test_images_path, \"w\")\n",
    "test_images_idx = load_features(test_num_img, test_num_feat, test_path, test_images)\n",
    "torch.save(test_images_idx, \"/ceph/kien/features/test_images.pt\")\n",
    "test_images.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

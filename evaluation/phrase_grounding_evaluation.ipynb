{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sonam/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "imported\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import sys\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow.contrib.slim as slim\n",
    "import tensorflow_hub as hub\n",
    "from utils import *\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "gpu_options = tf.GPUOptions(allow_growth=True)\n",
    "config = tf.ConfigProto(gpu_options=gpu_options,log_device_placement=True,allow_soft_placement=True)\n",
    "import lmdb\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pickle\n",
    "import collections\n",
    "print('imported')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f30k_path = '/dvmm-filer2/datasets/Groundings/data/flickr30k/'\n",
    "dict_paths_f30k = [f30k_path+'flickr30k_val.pickle',\n",
    "                   f30k_path+'flickr30k_test.pickle']\n",
    "\n",
    "ref_path = '/dvmm-filer2/datasets/Groundings/data/referit/referit_splits/'\n",
    "lmdb_path_ref = '/dvmm-filer2/datasets/Groundings/data/referit/refclef_data/all_data.lmdb'\n",
    "dict_path_ref = ref_path  +'test.pickle' \n",
    "\n",
    "vg_path = '/dvmm-filer2/datasets/Groundings/data/visualgenome/'\n",
    "dict_paths_vg = [vg_path+'train.pickle',\n",
    "                 vg_path+'val.pickle',\n",
    "                 vg_path+'test.pickle']\n",
    "lmdb_path_vg = vg_path+'data.lmdb'\n",
    "\n",
    "print('Loading Flickr30k...')\n",
    "#####Load Flickr30k\n",
    "\n",
    "# with open(dict_paths_f30k[0], 'rb') as f:\n",
    "#     dict_val_f30k = pickle.load(f, encoding='latin1')    \n",
    "    \n",
    "with open(dict_paths_f30k[1], 'rb') as f:\n",
    "    dict_test_f30k = pickle.load(f, encoding='latin1')   \n",
    "print('Loading ReferIt...')\n",
    "#####Load ReferIt\n",
    "with open(dict_path_ref, 'rb') as f:\n",
    "    dict_test_ref = pickle.load(f, encoding='latin1')\n",
    "    \n",
    "lmdb_env_ref = lmdb.open(lmdb_path_ref, map_size=int(1e11), readonly=True, lock=False)\n",
    "txn_ref = lmdb_env_ref.begin(write=False)\n",
    "\n",
    "print('Loading Visual Genome...')\n",
    "#####Load Visual Genome\n",
    "lmdb_env_vg = lmdb.open(lmdb_path_vg, map_size=int(1e11), readonly=True, lock=False)\n",
    "txn_vg = lmdb_env_vg.begin(write=False)\n",
    "\n",
    "# with open(dict_paths_vg[1], 'rb') as f:\n",
    "#     dict_val_vg = pickle.load(f, encoding='latin1')\n",
    "#     ids_val_vg = list(dict_val_vg.keys())\n",
    "    \n",
    "with open(dict_paths_vg[2], 'rb') as f:\n",
    "    dict_test_vg = pickle.load(f, encoding='latin1')\n",
    "    ids_test_vg = list(dict_test_vg.keys())\n",
    "    \n",
    "print('Loading data done.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correctness Measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# just measures how much is the attention map in the box\n",
    "def calc_correctness_fk(annot,heatmap,orig_img_shape):\n",
    "    bbox_dict = heat2bbox(heatmap,orig_img_shape)\n",
    "    bbox, bbox_norm, bbox_score = filter_bbox(bbox_dict=bbox_dict, order='xyxy')\n",
    "    bbox_norm_annot = union(annot['bbox_norm'])\n",
    "    bbox_annot = annot['bbox']\n",
    "    bbox_norm_pred = union(bbox_norm)\n",
    "    bbox_correctness = isCorrect(bbox_norm_annot, bbox_norm_pred, iou_thr=.5)\n",
    "    hit_correctness = isCorrectHit(bbox_annot,heatmap,orig_img_shape)\n",
    "    att_correctness = attCorrectNess(bbox_annot,heatmap,orig_img_shape)\n",
    "    return bbox_correctness,hit_correctness, att_correctness\n",
    "\n",
    "def calc_correctness_rit(annot, heatmap, orig_img_shape):\n",
    "    bbox_dict = heat2bbox(heatmap,orig_img_shape)\n",
    "    bbox, bbox_norm, bbox_score = filter_bbox(bbox_dict=bbox_dict, order='xyxy')\n",
    "    bbox_norm_annot = union(annot['bbox_norm'])\n",
    "    bbox_annot = union(annot['bbox'])\n",
    "    bbox_norm_pred = union(bbox_norm)\n",
    "    bbox_correctness = isCorrect(bbox_norm_annot, bbox_norm_pred, iou_thr=.5)\n",
    "    hit_correctness = isCorrectHit(bbox_annot, heatmap, orig_img_shape)\n",
    "    att_correctness = attCorrectNess(bbox_annot,heatmap,orig_img_shape)\n",
    "    return bbox_correctness, hit_correctness, att_correctness\n",
    "\n",
    "def calc_correctness_vg(annot, heatmap, orig_img_shape):\n",
    "    bbox_dict = heat2bbox(heatmap,orig_img_shape)\n",
    "    bbox, bbox_norm, bbox_score = filter_bbox(bbox_dict=bbox_dict, order='xyxy')\n",
    "    bbox_norm_annot = union(annot['bbox_norm'])\n",
    "    bbox_annot = union(annot['bbox'])\n",
    "    bbox_norm_pred = union(bbox_norm)\n",
    "    bbox_correctness = isCorrect(bbox_norm_annot, bbox_norm_pred, iou_thr=.5)\n",
    "    hit_correctness = isCorrectHit(bbox_annot, heatmap, orig_img_shape)\n",
    "    att_correctness = attCorrectNess(bbox_annot,heatmap,orig_img_shape)\n",
    "    return bbox_correctness, hit_correctness, att_correctness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validate_flickr30k_temp(dict_test):\n",
    "    cnt_overall = 0\n",
    "    cat_cnt_overall = {}\n",
    "    cnt_correct = 0\n",
    "    cat_cnt_correct = {}\n",
    "    cnt_correct_hit = 0\n",
    "    cnt_correct_att = 0\n",
    "    cat_cnt_correct_hit = {}\n",
    "    att_correct = 0\n",
    "    cat_att_correct = {}\n",
    "    wrd_idx_list = []\n",
    "    sen_idx_list = []\n",
    "    cat_lvl_scores = {}\n",
    "    layer0_words = set()\n",
    "    layer1_words = set()\n",
    "    layer3_words = set()\n",
    "    for k,doc_id in enumerate(dict_test):\n",
    "        if k>num_tst:\n",
    "            continue\n",
    "        img = np.reshape(cv2.resize(dict_test[doc_id]['img'],(299,299)),(1,299,299,3))\n",
    "        orig_img_shape = dict_test[doc_id]['size']\n",
    "        sen_batch = list(dict_test[doc_id]['sentences'].keys())\n",
    "        img_batch = np.repeat(img,len(sen_batch),axis=0)\n",
    "        tensor_list = [heatmap_w, R_i, R_s, lvl_idx_wrd, lvl_idx_sen, lvl_scr_wrd]\n",
    "        feed_dict = {input_img: img_batch, text_batch: sen_batch, mode: 'test'}\n",
    "        qry_heats, qry_scores, sen_score, wrd_idx, sen_idx, lvl_scores = sess.run(tensor_list, feed_dict)\n",
    "        # Getting embeddings for all sentences\n",
    "        sen_idx_list.extend(sen_idx) #level selected for each sentence \n",
    "        for c,sen in enumerate(sen_batch):\n",
    "            wrds = sen.split()\n",
    "            wrd_idx_list.extend(wrd_idx[c,:len(wrds)]) # For each sentence in image for each word the level selected\n",
    "            temp = wrd_idx[c,:len(wrds)]\n",
    "            \n",
    "            for i in range(len(temp)):\n",
    "                if temp[i]==0:\n",
    "                    layer0_words.add(wrds[i])\n",
    "                    \n",
    "                if temp[i]==1:\n",
    "                    layer1_words.add(wrds[i])\n",
    "                    \n",
    "                if temp[i]==3:\n",
    "                    layer3_words.add(wrds[i])\n",
    "                \n",
    "            for query in dict_test[doc_id]['sentences'][sen]:\n",
    "                #reject not groundable/acceptable queries\n",
    "                idx = dict_test[doc_id]['sentences'][sen][query]['idx']\n",
    "                if len(query.split())==0 or len(idx)==0: # idx where word in sentecne\n",
    "                    continue\n",
    "                annot = dict_test[doc_id]['sentences'][sen][query]\n",
    "                category = list(annot['category'])\n",
    "                if 'notvisual' in category or len(annot['bbox_norm'])==0:\n",
    "                    continue\n",
    "                if not check_percent(union(annot['bbox_norm'])):\n",
    "                    continue\n",
    "                #if reaches this point, it is groundable/acceptable\n",
    "                cnt_overall+=1\n",
    "                for cat in category:\n",
    "                    if cat not in cat_cnt_overall:\n",
    "                        cat_cnt_overall[cat] = 0\n",
    "                    cat_cnt_overall[cat]+=1    \n",
    "                \n",
    "                if np.mean(qry_scores[c,idx])==0:\n",
    "                    pred = {}\n",
    "                else:\n",
    "                    heatmap = np.average(qry_heats[c,idx,:], weights = qry_scores[c,idx], axis=0)\n",
    "                    # calculate hit, box, attention for query\n",
    "                    bbox_c, hit_c, att_c = calc_correctness_fk(annot,heatmap,orig_img_shape)\n",
    "                    \n",
    "                    cnt_correct += bbox_c\n",
    "                    cnt_correct_hit += hit_c\n",
    "                    cnt_correct_att += att_c\n",
    "                    for cat in category:\n",
    "                        #per-cat lvl score\n",
    "                        if cat not in cat_lvl_scores:\n",
    "                            cat_lvl_scores[cat] = []\n",
    "                        cat_lvl_scores[cat].append(lvl_scores[c,idx,:])\n",
    "                        \n",
    "                        #per-cat bbox acc\n",
    "                        if cat not in cat_cnt_correct:\n",
    "                            cat_cnt_correct[cat] = 0\n",
    "                        cat_cnt_correct[cat] += bbox_c\n",
    "                        \n",
    "                        #per-cat hit acc\n",
    "                        if cat not in cat_cnt_correct_hit:\n",
    "                            cat_cnt_correct_hit[cat] = 0\n",
    "                        cat_cnt_correct_hit[cat] += hit_c\n",
    "                        \n",
    "                        #per-cat att acc\n",
    "                        #cat_att_correct\n",
    "                        if cat not in cat_att_correct:\n",
    "                            cat_att_correct[cat] = []\n",
    "                        cat_att_correct[cat].append(att_c)\n",
    "                    \n",
    "        var = [k,num_tst,100.*cnt_correct/cnt_overall,100.*cnt_correct_hit/cnt_overall]\n",
    "        prnt = 'Sample {}/{}, IoU_acc:{:.2f}, Hit_acc:{:.2f} \\r'.format(var[0],var[1],var[2],var[3])\n",
    "        sys.stdout.write(prnt)                \n",
    "        sys.stdout.flush()\n",
    "    \n",
    "    #overall acc\n",
    "    hit_acc = cnt_correct_hit/cnt_overall\n",
    "    iou_acc = cnt_correct/cnt_overall\n",
    "    att_acc = cnt_correct_att/cnt_overall\n",
    "    tmp = cat_att_correct\n",
    "    #cat-wise acc\n",
    "    for cat in cat_cnt_correct:\n",
    "        cat_cnt_correct[cat]/=cat_cnt_overall[cat]\n",
    "    for cat in cat_cnt_correct_hit:\n",
    "        cat_cnt_correct_hit[cat]/=cat_cnt_overall[cat]\n",
    "    for cat in cat_att_correct:\n",
    "        cat_att_correct[cat]=np.mean(cat_att_correct[cat])\n",
    "    \n",
    "    #return tmp, cat_att_correct,cnt_overall,\n",
    "        \n",
    "    return layer0_words, layer1_words,layer3_words,iou_acc,hit_acc,att_acc,wrd_idx_list,sen_idx_list,cat_lvl_scores,cat_cnt_correct,cat_cnt_correct_hit,cat_att_correct\n",
    "\n",
    "\n",
    "def validate_flickr30k(dict_test):\n",
    "    cnt_overall = 0\n",
    "    cat_cnt_overall = {}\n",
    "    cnt_correct = 0\n",
    "    cat_cnt_correct = {}\n",
    "    cnt_correct_hit = 0\n",
    "    cnt_correct_att = 0\n",
    "    cat_cnt_correct_hit = {}\n",
    "    att_correct = 0\n",
    "    cat_att_correct = {}\n",
    "    wrd_idx_list = []\n",
    "    sen_idx_list = []\n",
    "    cat_lvl_scores = {}\n",
    "    for k,doc_id in enumerate(dict_test):\n",
    "        if k>num_tst:\n",
    "            continue\n",
    "        img = np.reshape(cv2.resize(dict_test[doc_id]['img'],(299,299)),(1,299,299,3))\n",
    "        orig_img_shape = dict_test[doc_id]['size']\n",
    "        sen_batch = list(dict_test[doc_id]['sentences'].keys())\n",
    "        img_batch = np.repeat(img,len(sen_batch),axis=0)\n",
    "        tensor_list = [heatmap_w, R_i, R_s, lvl_idx_wrd, lvl_idx_sen, lvl_scr_wrd]\n",
    "        feed_dict = {input_img: img_batch, text_batch: sen_batch, mode: 'test'}\n",
    "        qry_heats, qry_scores, sen_score, wrd_idx, sen_idx, lvl_scores = sess.run(tensor_list, feed_dict)\n",
    "        # Getting embeddings for all sentences\n",
    "        sen_idx_list.extend(sen_idx) #level selected for each sentence \n",
    "        for c,sen in enumerate(sen_batch):\n",
    "            wrds = sen.split()\n",
    "            wrd_idx_list.extend(wrd_idx[c,:len(wrds)]) # For each sentence in image for each word the level selected\n",
    "            for query in dict_test[doc_id]['sentences'][sen]:\n",
    "                #reject not groundable/acceptable queries\n",
    "                idx = dict_test[doc_id]['sentences'][sen][query]['idx']\n",
    "                if len(query.split())==0 or len(idx)==0: # idx where word in sentecne\n",
    "                    continue\n",
    "                annot = dict_test[doc_id]['sentences'][sen][query]\n",
    "                category = list(annot['category'])\n",
    "                if 'notvisual' in category or len(annot['bbox_norm'])==0:\n",
    "                    continue\n",
    "                if not check_percent(union(annot['bbox_norm'])):\n",
    "                    continue\n",
    "                #if reaches this point, it is groundable/acceptable\n",
    "                cnt_overall+=1\n",
    "                for cat in category:\n",
    "                    if cat not in cat_cnt_overall:\n",
    "                        cat_cnt_overall[cat] = 0\n",
    "                    cat_cnt_overall[cat]+=1    \n",
    "                \n",
    "                if np.mean(qry_scores[c,idx])==0:\n",
    "                    pred = {}\n",
    "                else:\n",
    "                    heatmap = np.average(qry_heats[c,idx,:], weights = qry_scores[c,idx], axis=0)\n",
    "                    # calculate hit, box, attention for query\n",
    "                    bbox_c, hit_c, att_c = calc_correctness_fk(annot,heatmap,orig_img_shape)\n",
    "                    \n",
    "                    cnt_correct += bbox_c\n",
    "                    cnt_correct_hit += hit_c\n",
    "                    cnt_correct_att += att_c\n",
    "                    for cat in category:\n",
    "                        #per-cat lvl score\n",
    "                        if cat not in cat_lvl_scores:\n",
    "                            cat_lvl_scores[cat] = []\n",
    "                        cat_lvl_scores[cat].append(lvl_scores[c,idx,:])\n",
    "                        \n",
    "                        #per-cat bbox acc\n",
    "                        if cat not in cat_cnt_correct:\n",
    "                            cat_cnt_correct[cat] = 0\n",
    "                        cat_cnt_correct[cat] += bbox_c\n",
    "                        \n",
    "                        #per-cat hit acc\n",
    "                        if cat not in cat_cnt_correct_hit:\n",
    "                            cat_cnt_correct_hit[cat] = 0\n",
    "                        cat_cnt_correct_hit[cat] += hit_c\n",
    "                        \n",
    "                        #per-cat att acc\n",
    "                        #cat_att_correct\n",
    "                        if cat not in cat_att_correct:\n",
    "                            cat_att_correct[cat] = []\n",
    "                        cat_att_correct[cat].append(att_c)\n",
    "                    \n",
    "        var = [k,num_tst,100.*cnt_correct/cnt_overall,100.*cnt_correct_hit/cnt_overall]\n",
    "        prnt = 'Sample {}/{}, IoU_acc:{:.2f}, Hit_acc:{:.2f} \\r'.format(var[0],var[1],var[2],var[3])\n",
    "        sys.stdout.write(prnt)                \n",
    "        sys.stdout.flush()\n",
    "    \n",
    "    #overall acc\n",
    "    hit_acc = cnt_correct_hit/cnt_overall\n",
    "    iou_acc = cnt_correct/cnt_overall\n",
    "    att_acc = cnt_correct_att/cnt_overall\n",
    "    tmp = cat_att_correct\n",
    "    #cat-wise acc\n",
    "    for cat in cat_cnt_correct:\n",
    "        cat_cnt_correct[cat]/=cat_cnt_overall[cat]\n",
    "    for cat in cat_cnt_correct_hit:\n",
    "        cat_cnt_correct_hit[cat]/=cat_cnt_overall[cat]\n",
    "    for cat in cat_att_correct:\n",
    "        cat_att_correct[cat]=np.mean(cat_att_correct[cat])\n",
    "    \n",
    "    #return tmp, cat_att_correct,cnt_overall,\n",
    "        \n",
    "    return iou_acc,hit_acc,att_acc,wrd_idx_list,sen_idx_list,cat_lvl_scores,cat_cnt_correct,cat_cnt_correct_hit,cat_att_correct\n",
    "\n",
    "def validate_vg_new(dict_test,txn):\n",
    "    cnt_overall = 0\n",
    "    cnt_correct_w = 0\n",
    "    cnt_correct_hit_w = 0\n",
    "    cnt_correct_s = 0\n",
    "    cnt_correct_hit_s = 0\n",
    "    cnt_correct_att_s = 0\n",
    "    cnt_correct_att_w = 0\n",
    "    \n",
    "    wrd_idx_list = []\n",
    "    sen_idx_list = []\n",
    "    for k,doc_id in enumerate(dict_test):\n",
    "        if k>num_tst:\n",
    "            continue\n",
    "        imgbin = txn.get(doc_id.encode('utf-8'))\n",
    "        if imgbin==None:\n",
    "            continue\n",
    "        buff = np.frombuffer(imgbin, dtype='uint8')\n",
    "        if len(buff) == 0:\n",
    "            continue\n",
    "        imgbgr = cv2.imdecode(buff, cv2.IMREAD_COLOR)\n",
    "        imgrgb = imgbgr[:,:,[2,1,0]]\n",
    "\n",
    "        img = np.reshape(cv2.resize(imgrgb,(299,299)),(1,299,299,3))\n",
    "        orig_img_shape = dict_test[doc_id]['size'][:2]\n",
    "        \n",
    "        sen_batch = []\n",
    "        annot_batch = []\n",
    "        #create batch of queries in a doc_id annotation\n",
    "        for i,annot in enumerate(dict_test[doc_id]['annotations']):\n",
    "            sen = annot['query']\n",
    "            if len(sen.split())==0 or len(annot['bbox_norm'])== 0:\n",
    "                continue\n",
    "            if not check_percent(union(annot['bbox_norm'])):\n",
    "                continue\n",
    "            if any(b>1 for b in annot['bbox_norm']):\n",
    "                continue\n",
    "            sen_batch.append(sen)\n",
    "            annot_batch.append(annot)\n",
    "        if len(sen_batch)==0:\n",
    "            continue\n",
    "        cnt_overall += len(sen_batch)\n",
    "\n",
    "        img_batch = np.repeat(img,len(sen_batch),axis=0)\n",
    "        tensor_list = [heatmap_w,heatmap_s, R_i, R_s, lvl_idx_wrd, lvl_idx_sen, lvl_scr_wrd]\n",
    "        feed_dict = {input_img: img_batch, text_batch: sen_batch, mode: 'test'}\n",
    "        qry_heats,qry_heat, qry_scores, sen_score, wrd_idx, sen_idx, lvl_scores = sess.run(tensor_list, feed_dict)\n",
    "        sen_idx_list.extend(sen_idx) \n",
    "        \n",
    "        for c,sen in enumerate(sen_batch):\n",
    "            idx = [j for j in range(len(sen.split()))]\n",
    "            wrds = sen.split()\n",
    "            wrd_idx_list.extend(wrd_idx[c,:len(wrds)])\n",
    "            if np.mean(qry_scores[c,idx])==0:\n",
    "                pred = {}\n",
    "            else:\n",
    "                heatmap_wrd = np.average(qry_heats[c,idx,:], weights = qry_scores[c,idx], axis=0)\n",
    "                heatmap_sen = qry_heat[c,:]\n",
    "                bbox_c_w,hit_c_w,att_c_w = calc_correctness_vg(annot_batch[c],heatmap_wrd,orig_img_shape)\n",
    "                bbox_c_s,hit_c_s,att_c_s = calc_correctness_vg(annot_batch[c],heatmap_sen,orig_img_shape)\n",
    "                cnt_correct_w += bbox_c_w\n",
    "                cnt_correct_hit_w += hit_c_w\n",
    "                cnt_correct_s += bbox_c_s\n",
    "                cnt_correct_hit_s += hit_c_s\n",
    "                cnt_correct_att_w += att_c_w \n",
    "                cnt_correct_att_s += att_c_s\n",
    "\n",
    "        var = [k,num_tst,cnt_correct_w/cnt_overall,cnt_correct_hit_w/cnt_overall]\n",
    "        var_s = [cnt_correct_s/cnt_overall,cnt_correct_hit_s/cnt_overall]\n",
    "        prnt0 = 'Sample {}/{}, IoU_acc_w:{:.2f}, IoU_acc_s:{:.2f}'.format(var[0],var[1],var[2],var_s[0])\n",
    "        prnt1 = ', Hit_acc_w:{:.2f}, Hit_acc_s:{:.2f} \\r'.format(var[3],var_s[1])\n",
    "        sys.stdout.write(prnt0+prnt1)                \n",
    "        sys.stdout.flush()\n",
    "\n",
    "    hit_acc_w = cnt_correct_hit_w/cnt_overall\n",
    "    iou_acc_w = cnt_correct_w/cnt_overall\n",
    "    hit_acc_s = cnt_correct_hit_s/cnt_overall\n",
    "    iou_acc_s = cnt_correct_s/cnt_overall\n",
    "    att_acc_w = cnt_correct_att_w/cnt_overall\n",
    "    att_acc_s = cnt_correct_att_s/cnt_overall\n",
    "    \n",
    "    return iou_acc_w, hit_acc_w,att_acc_w,iou_acc_s, hit_acc_s, att_acc_s, wrd_idx_list, sen_idx_list\n",
    "\n",
    "\n",
    "def validate_referit_new(dict_test,txn):\n",
    "    cnt_overall = 0\n",
    "    cnt_correct_w = 0\n",
    "    cnt_correct_hit_w = 0\n",
    "    cnt_correct_s = 0\n",
    "    cnt_correct_hit_s = 0\n",
    "    cnt_correct_att_s = 0\n",
    "    cnt_correct_att_w = 0\n",
    "    wrd_idx_list = []\n",
    "    sen_idx_list = []\n",
    "    for k,doc_id in enumerate(dict_test):\n",
    "        if k>num_tst:\n",
    "            continue\n",
    "        imgbin = txn.get(doc_id.encode('utf-8'))\n",
    "        if imgbin==None:\n",
    "            print (\"Image not found\")\n",
    "            continue\n",
    "        buff = np.frombuffer(imgbin, dtype='uint8')\n",
    "        if len(buff) == 0:\n",
    "            print (\"Image not found\")\n",
    "            continue\n",
    "        imgbgr = cv2.imdecode(buff, cv2.IMREAD_COLOR)\n",
    "        imgrgb = imgbgr[:,:,[2,1,0]]\n",
    "\n",
    "        img = np.reshape(cv2.resize(imgrgb,(299,299)),(1,299,299,3))\n",
    "        orig_img_shape = dict_test[doc_id]['size'][:2]\n",
    "\n",
    "        for i,annot in enumerate(dict_test[doc_id]['annotations']):\n",
    "            if len(annot['bbox_norm'])== 0:\n",
    "                continue\n",
    "            if not check_percent(union(annot['bbox_norm'])):\n",
    "                continue\n",
    "            if any(b>1 for b in annot['bbox_norm']):\n",
    "                continue\n",
    "            unq_qry = set(annot['query'])\n",
    "            sen_batch = [sen for sen in unq_qry if 0<len(sen.split())<=50] #only unique queries with 0<length<=50\n",
    "            img_batch = np.repeat(img,len(sen_batch),axis=0)\n",
    "            tensor_list = [heatmap_w, heatmap_s,R_i, R_s, lvl_idx_wrd, lvl_idx_sen, lvl_scr_wrd]\n",
    "            feed_dict = {input_img: img_batch, text_batch: sen_batch, mode: 'test'}\n",
    "            \n",
    "            qry_heats, qry_heat, qry_scores, sen_score, wrd_idx, sen_idx, lvl_scores = sess.run(tensor_list, feed_dict)\n",
    "            sen_idx_list.extend(sen_idx)\n",
    "            cnt_overall += len(sen_batch)\n",
    "            for c,sen in enumerate(sen_batch):\n",
    "                idx = [j for j in range(len(sen.split()))]\n",
    "                if np.mean(qry_scores[c,idx])==0:\n",
    "                    pred = {}\n",
    "                else:\n",
    "                    wrds = sen.split()\n",
    "                    wrd_idx_list.extend(wrd_idx[c,:len(wrds)])\n",
    "                    heatmap_wrd = np.average(qry_heats[c,idx,:], weights = qry_scores[c,idx], axis=0)\n",
    "                    heatmap_sen = qry_heat[c,:]\n",
    "                    bbox_c_w, hit_c_w, att_c_w = calc_correctness_rit(annot,heatmap_wrd,orig_img_shape)\n",
    "                    bbox_c_s, hit_c_s, att_c_s = calc_correctness_rit(annot,heatmap_sen,orig_img_shape)\n",
    "                    cnt_correct_w += bbox_c_w\n",
    "                    cnt_correct_hit_w += hit_c_w\n",
    "                    cnt_correct_s += bbox_c_s\n",
    "                    cnt_correct_hit_s += hit_c_s\n",
    "                    cnt_correct_att_w += att_c_w \n",
    "                    cnt_correct_att_s += att_c_s\n",
    "                                     \n",
    "        var = [k,num_tst,cnt_correct_w/cnt_overall,cnt_correct_hit_w/cnt_overall]\n",
    "        var_s = [cnt_correct_s/cnt_overall,cnt_correct_hit_s/cnt_overall]\n",
    "        prnt0 = 'Sample {}/{}, IoU_acc_w:{:.2f}, IoU_acc_s:{:.2f}'.format(var[0],var[1],var[2],var_s[0])\n",
    "        prnt1 = ', Hit_acc_w:{:.2f}, Hit_acc_s:{:.2f} \\r'.format(var[3],var_s[1])\n",
    "        sys.stdout.write(prnt0+prnt1)                \n",
    "        sys.stdout.flush()\n",
    "\n",
    "    hit_acc_w = cnt_correct_hit_w/cnt_overall\n",
    "    iou_acc_w = cnt_correct_w/cnt_overall\n",
    "    hit_acc_s = cnt_correct_hit_s/cnt_overall\n",
    "    iou_acc_s = cnt_correct_s/cnt_overall\n",
    "    att_acc_w = cnt_correct_att_w/cnt_overall\n",
    "    att_acc_s = cnt_correct_att_s/cnt_overall\n",
    "    \n",
    "    return iou_acc_w, hit_acc_w,att_acc_w,iou_acc_s, hit_acc_s, att_acc_s, wrd_idx_list, sen_idx_list\n",
    "\n",
    "def attCorrectNess(bbox_annot,heatmap,orig_img_shape):\n",
    "    H,W = orig_img_shape\n",
    "    heatmap_resized = cv2.resize(heatmap, (W, H))\n",
    "    h_s = np.sum(heatmap_resized)\n",
    "    if h_s==0:\n",
    "        return 0\n",
    "    else:\n",
    "        heatmap_resized /= h_s\n",
    "    att_correctness = 0\n",
    "    for bbox in bbox_annot:\n",
    "        x0,y0,x1,y1=bbox\n",
    "        att_correctness+=np.sum(heatmap_resized[int(y0):int(y1),int(x0):int(x1)])\n",
    "    return att_correctness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def attn(e_w,v,e_s):\n",
    "    ## Inputs: local and global cap and img features ##\n",
    "    ## Output: Heatmap for each word, Global Heatmap, Attnded Vis features, Corr-vals\n",
    "    #e: ?xTxD, v: ?xNx4xD, e_bar: ?xD\n",
    "    with tf.variable_scope('attention'):\n",
    "        ###word-level###\n",
    "        #heatmap pool\n",
    "        h = tf.nn.relu(tf.einsum('bij,bklj->bikl',e_w,v)) #pair-wise ev^T: ?xTxNx4\n",
    "        #attention\n",
    "        a = tf.einsum('bijk,bjkl->bilk',h,v) #?xTxDx4 attnded visual reps for each of T words\n",
    "        #pair-wise score\n",
    "        a_norm = tf.nn.l2_normalize(a,axis=2)\n",
    "        e_w_norm = tf.nn.l2_normalize(e_w,axis=2)\n",
    "        R_ik = tf.einsum('bilk,bil->bik',a_norm,e_w_norm) #cosine for T (words,img_reps) for all pairs\n",
    "        \n",
    "        R_ik = tf.identity(R_ik,name='level_score_word')\n",
    "        R_i = tf.reduce_max(R_ik,axis=-1,name='score_word') #?xT\n",
    "        #R = tf.log(tf.pow(tf.reduce_sum(tf.exp(gamma_1*R_i),axis=1),1/gamma_1)) #? corrs\n",
    "        #heatmap\n",
    "        idx_i = tf.argmax(R_ik,axis=-1,name='level_index_word') #?xT index of the featuremap which maximizes R_i\n",
    "        with tf.name_scope('summaries'):\n",
    "            tf.summary.histogram('histogram_w', idx_i)\n",
    "        ii,jj = tf.meshgrid(tf.range(tf.shape(idx_i)[0]),tf.range(tf.shape(idx_i)[1]),indexing='ij')\n",
    "        ii = tf.cast(ii,tf.int64)\n",
    "        jj = tf.cast(jj,tf.int64)\n",
    "        batch_idx_i = tf.stack([tf.reshape(ii,(-1,)),\n",
    "                                tf.reshape(jj,(-1,)),\n",
    "                                tf.reshape(idx_i,(-1,))],axis=1) #?Tx3 indices of argmax\n",
    "        N0=int(np.sqrt(h.get_shape().as_list()[2]))\n",
    "        h_max = tf.gather_nd(tf.transpose(h,[0,1,3,2]),batch_idx_i) #?TxN retrieving max heatmaps\n",
    "        heatmap_wd = tf.reshape(h_max,[tf.shape(h)[0],tf.shape(h)[1],N0,N0],name='heatmap_word')\n",
    "        heatmap_wd_l = tf.reshape(h,[tf.shape(h)[0],tf.shape(h)[1],N0,N0,tf.shape(h)[3]],name='level_heatmap_word')\n",
    "        \n",
    "        ###sentence-level###\n",
    "        #heatmap pool\n",
    "        h_s = tf.nn.relu(tf.einsum('bj,blkj->blk',e_s,v)) #pair-wise e_bar*v^T: ?xNx4\n",
    "        #attention\n",
    "        a_s = tf.einsum('bjk,bjki->bik',h_s,v) #?xDx4 attnded visual reps for sen.\n",
    "        #pair-wise score\n",
    "        a_s_norm = tf.nn.l2_normalize(a_s,axis=1)\n",
    "        e_s_norm = tf.nn.l2_normalize(e_s,axis=1)\n",
    "        R_sk = tf.einsum('bik,bi->bk',a_s_norm,e_s_norm) #cosine for (sen,img_reps)\n",
    "        R_sk = tf.identity(R_sk,name='level_score_sentence')\n",
    "        R_s = tf.reduce_mean(R_sk,axis=-1,name='score_sentence') #?\n",
    "        #heatmap\n",
    "        idx_k = tf.argmax(R_sk,axis=-1,name='level_index_sentence') #? index of the featuremap which maximizes R_i\n",
    "        with tf.name_scope('summaries'):\n",
    "            tf.summary.histogram('histogram_s', idx_k)\n",
    "        ii_k = tf.cast(tf.range(tf.shape(idx_k)[0]),dtype='int64')\n",
    "        batch_idx_k = tf.stack([ii_k,idx_k],axis=1)\n",
    "        N0_g=int(np.sqrt(h_s.get_shape().as_list()[1]))\n",
    "        h_s_max = tf.gather_nd(tf.transpose(h_s,[0,2,1]),batch_idx_k) #?xN retrieving max heatmaps\n",
    "        heatmap_sd = tf.reshape(h_s_max,[-1,N0_g,N0_g],name='heatmap_sentence')\n",
    "        heatmap_sd_l = tf.reshape(h_s,[-1,N0_g,N0_g,tf.shape(h)[3]],name='level_heatmap_sentence')\n",
    "        \n",
    "    return heatmap_wd, heatmap_sd, R_i, R_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_name = ['model_Performance_AttnGrnd_VGG_Depth_Max_VG_3by3_maxpool_nlayer4',\n",
    "             'model_Performance_AttnGrnd_VGG_Depth_Max_VG_3by3_maxpool_nlayer3',\n",
    "             'model_Performance_AttnGrnd_VGG_Depth_Max_VG_3by3_maxpool_nlayer2',\n",
    "             'model_Performance_AttnGrnd_VGG_Depth_Max_VG_3by3_maxpool_nlayer1',\n",
    "             'model_AttnGrnd_VGG_Depth_Max_VG_maxpool',\n",
    "             'model_AttnGrnd_VGG_Depth_Max_VG_best_hit',\n",
    "             'model_Performance_AttnGrnd_VGG_Depth_Max_VG_3by3_resize_nlayer1',\n",
    "             'model_Performance_AttnGrnd_PNAS_Depth_Max_VG_3by3_resize_nlayer1',\n",
    "               'model_Performance_AttnGrnd_PNAS_Depth_Max_VG_1by1_3by3_resize_nlayer2',\n",
    "             'model_Performance_AttnGrnd_PNAS_Depth_Max_VG_3by3_resize_nlayer_first2_sec12']\n",
    "           \n",
    "print(len(model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#loading grounding pretrained model\n",
    "condition = model_name[9]\n",
    "print('Loading grounding pretrained model...')\n",
    "model_path = './saved_models/'+ condition\n",
    "print(model_path)\n",
    "#model_path = '../model_CNN_avg'\n",
    "sess, graph = load_model(model_path,config)\n",
    "print('Model Loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tf.all_variables()\n",
    "#sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#heatmap_wd, heatmap_sd, R_i, R_s = attn(e_w,v,e_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# t = sess.graph.get_tensor_by_name(\"attention/level_heatmap_word:0\")\n",
    "# print(t.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_img = sess.graph.get_tensor_by_name(\"input_img:0\")\n",
    "text_batch = sess.graph.get_tensor_by_name(\"text_input:0\")\n",
    "mode = sess.graph.get_tensor_by_name(\"mode:0\")\n",
    "e_w = sess.graph.get_tensor_by_name(\"w_embedding:0\")\n",
    "e_s = sess.graph.get_tensor_by_name(\"sen_embedding:0\")\n",
    "v = sess.graph.get_tensor_by_name(\"stack_v/stacked_image_feature_maps:0\")\n",
    "heatmap_wd, heatmap_sd, R_i, R_s = attn(e_w,v,e_s)\n",
    "print(R_i.shape)\n",
    "\n",
    "R_i = sess.graph.get_tensor_by_name(\"attention/score_word:0\")#/transpose_2\n",
    "R_s = sess.graph.get_tensor_by_name(\"attention/score_sentence:0\")\n",
    "heatmap_w = sess.graph.get_tensor_by_name(\"attention/heatmap_word:0\")\n",
    "heatmap_s = sess.graph.get_tensor_by_name(\"attention/heatmap_sentence:0\")\n",
    "\n",
    "#heatmap_wk = sess.graph.get_tensor_by_name(\"attention/level_heatmap_word:0\")\n",
    "#heatmap_sk = sess.graph.get_tensor_by_name(\"attention/level_heatmap_sentence:0\")\n",
    "lvl_idx_wrd = sess.graph.get_tensor_by_name('attention/level_index_word:0') #level mazimising each word T\n",
    "lvl_scr_wrd = sess.graph.get_tensor_by_name('attention/level_score_word:0') #score for level mazimising each word T\n",
    "lvl_idx_sen = sess.graph.get_tensor_by_name('attention/level_index_sentence:0')#level mazimising sentence\n",
    "#lvl_idx_wrd = sess.graph.get_tensor_by_name('attention/ArgMax:0')\n",
    "#lvl_scr_wrd = sess.graph.get_tensor_by_name('attention/einsum_2/transpose_2:0')\n",
    "#lvl_idx_sen = sess.graph.get_tensor_by_name('attention/ArgMax_1:0')\n",
    "print('Loading done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Flickr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(len(dict_test_f30k))\n",
    "# print(dict_test_f30k['4842876705'])\n",
    "#print(dict_test_f30k['4842876705']['sentences'].keys())\n",
    "#print(dict_test_f30k['4842876705']['sentences']['A man in a blue shirt and jeans plays bass on the street .']['A man'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#temp\n",
    "#### Flickr30k ####\n",
    "print('Test on Flickr30k\\n')\n",
    "num_tst = len(dict_test_f30k)\n",
    "num_tst = 100\n",
    "layer0, layer1,layer3, iou_acc_f30k, hit_acc_f30k, att_acc_f30k, wrd_idx_list_f30k,sen_idx_list_f30k,cat_lvl_scores_f30k,cat_iou_acc_f30k,cat_hit_acc_f30k,cat_att_acc_f30k = validate_flickr30k_temp(dict_test_f30k)\n",
    "print('done testing')\n",
    "print('flickr')\n",
    "print('wrds for layer0', layer0)\n",
    "print('wrds for layer1', layer1)\n",
    "print(collections.Counter(wrd_idx_list_f30k))\n",
    "print(collections.Counter(sen_idx_list_f30k))\n",
    "print(cat_lvl_scores_f30k['clothing'][2])\n",
    "print('Cat_acc\\n', cat_iou_acc_f30k)\n",
    "print('Cat hit\\n', cat_hit_acc_f30k)\n",
    "print('Cat att\\n', cat_att_acc_f30k)\n",
    "print('iou_acc',iou_acc_f30k)\n",
    "print('hit_acc',hit_acc_f30k)\n",
    "print('att_acc',att_acc_f30k)\n",
    "print('start saving')\n",
    "# with open('./evaluations/train_vg/test_f30k/'+condition+'.pickle', 'wb') as f:\n",
    "#     pickle.dump({'iou_acc':iou_acc_f30k,\n",
    "#                  'hit_acc':hit_acc_f30k,\n",
    "#                  'att_acc':att_acc_f30k,\n",
    "#                  'wrd_idx_list':wrd_idx_list_f30k,\n",
    "#                  'sen_idx_list':sen_idx_list_f30k,\n",
    "#                  'cat_lvl_scores':cat_lvl_scores_f30k,\n",
    "#                  'cat_iou_acc':cat_iou_acc_f30k,\n",
    "#                  'cat_hit_acc':cat_hit_acc_f30k,\n",
    "#                  'cat_att_acc':cat_att_acc_f30k},f,protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('0',layer0)\n",
    "print('1',layer1)\n",
    "print('3',layer3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Flickr30k ####\n",
    "print('Test on Flickr30k\\n')\n",
    "num_tst = len(dict_test_f30k)\n",
    "num_tst = 50\n",
    "iou_acc_f30k, hit_acc_f30k, att_acc_f30k, wrd_idx_list_f30k,sen_idx_list_f30k,cat_lvl_scores_f30k,cat_iou_acc_f30k,cat_hit_acc_f30k,cat_att_acc_f30k = validate_flickr30k(dict_test_f30k)\n",
    "print('done testing')\n",
    "print('flickr')\n",
    "print(collections.Counter(wrd_idx_list_f30k))\n",
    "print(collections.Counter(sen_idx_list_f30k))\n",
    "print(cat_lvl_scores_f30k['clothing'][2])\n",
    "print('Cat_acc\\n', cat_iou_acc_f30k)\n",
    "print('Cat hit\\n', cat_hit_acc_f30k)\n",
    "print('Cat att\\n', cat_att_acc_f30k)\n",
    "print('iou_acc',iou_acc_f30k)\n",
    "print('hit_acc',hit_acc_f30k)\n",
    "print('att_acc',att_acc_f30k)\n",
    "print('start saving')\n",
    "# with open('./evaluations/train_vg/test_f30k/'+condition+'.pickle', 'wb') as f:\n",
    "#     pickle.dump({'iou_acc':iou_acc_f30k,\n",
    "#                  'hit_acc':hit_acc_f30k,\n",
    "#                  'att_acc':att_acc_f30k,\n",
    "#                  'wrd_idx_list':wrd_idx_list_f30k,\n",
    "#                  'sen_idx_list':sen_idx_list_f30k,\n",
    "#                  'cat_lvl_scores':cat_lvl_scores_f30k,\n",
    "#                  'cat_iou_acc':cat_iou_acc_f30k,\n",
    "#                  'cat_hit_acc':cat_hit_acc_f30k,\n",
    "#                  'cat_att_acc':cat_att_acc_f30k},f,protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# !pip install jupyter_contrib_nbextensions\n",
    "# !jupyter contrib nbextension install --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# # Evaluation ReferIt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(dict_test_ref['14730']['captions'])\n",
    "#print(dict_test_ref['14730']['annotations'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Test on ReferIt\\n')\n",
    "#### ReferIt ####\n",
    "num_tst = len(dict_test_ref)\n",
    "iou_acc_ref_w, hit_acc_ref_w,att_acc_ref_w, iou_acc_ref_s, hit_acc_ref_s,att_acc_ref_s, wrd_idx_list_ref, sen_idx_list_ref = validate_referit_new(dict_test_ref,txn_ref)\n",
    "print('referit')\n",
    "print(collections.Counter(wrd_idx_list_ref))\n",
    "print(collections.Counter(sen_idx_list_ref))\n",
    "print('iou_acc_word',iou_acc_ref_w)\n",
    "print('iou_acc_sent',iou_acc_ref_s)\n",
    "print('hit_acc_word',hit_acc_ref_w)\n",
    "print('hit_acc_sent',hit_acc_ref_s)\n",
    "print('att_acc_sent',att_acc_ref_s)\n",
    "print('att_acc_word',att_acc_ref_w)\n",
    "with open('./evaluations/train_vg/test_referit/'+condition+'.pickle', 'wb') as f:\n",
    "    pickle.dump({'iou_acc_w':iou_acc_ref_w,\n",
    "                 'hit_acc_w':hit_acc_ref_w,\n",
    "                  'att_acc_w':att_acc_ref_w,\n",
    "                 'iou_acc_s':iou_acc_ref_s,\n",
    "                 'hit_acc_s':hit_acc_ref_s,\n",
    "                 'att_acc_s':att_acc_ref_s,\n",
    "                 'wrd_idx_list':wrd_idx_list_ref,\n",
    "                 'sen_idx_list':sen_idx_list_ref},f,protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print('All Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation VisualGenome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#print(dict_test_vg['2345650']['annotations'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Test on Visual Genome\\n')\n",
    "#### Visual Genome ####\n",
    "num_tst = len(dict_test_vg)\n",
    "iou_acc_vg_w, hit_acc_vg_w, att_acc_vg_w, iou_acc_vg_s, hit_acc_vg_s, att_acc_vg_s, wrd_idx_list_vg ,sen_idx_list_vg = validate_vg_new(dict_test_vg,txn_vg)\n",
    "print('All done.')\n",
    "print('visualgenome')\n",
    "print(collections.Counter(wrd_idx_list_vg))\n",
    "print(collections.Counter(sen_idx_list_vg))\n",
    "print('iou_acc_word',iou_acc_vg_w)\n",
    "print('iou_acc_sent',iou_acc_vg_s)\n",
    "print('hit_acc_word',hit_acc_vg_w)\n",
    "print('hit_acc_sent',hit_acc_vg_s)\n",
    "print('att_acc_sent',att_acc_vg_s)\n",
    "print('att_acc_word',att_acc_vg_w)\n",
    "with open('./evaluations/train_vg/test_vg/'+condition+'.pickle', 'wb') as f:\n",
    "    pickle.dump({'iou_acc_w':iou_acc_vg_w,\n",
    "                 'hit_acc_w':hit_acc_vg_w,\n",
    "                  'att_acc_w':att_acc_vg_w,\n",
    "                 'iou_acc_s':iou_acc_vg_s,\n",
    "                 'hit_acc_s':hit_acc_vg_s,\n",
    "                 'att_acc_s':att_acc_vg_s,\n",
    "                 'wrd_idx_list':wrd_idx_list_vg,\n",
    "                 'sen_idx_list':sen_idx_list_vg},f,protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print('AllDone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('sonam')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Test on Flickr30k\\n')\n",
    "num_tst = len(dict_test_f30k)\n",
    "iou_acc_f30k, hit_acc_f30k, att_acc_f30k, wrd_idx_list_f30k,sen_idx_list_f30k,cat_lvl_scores_f30k,cat_iou_acc_f30k,cat_hit_acc_f30k,cat_att_acc_f30k = validate_flickr30k(dict_test_f30k)\n",
    "\n",
    "print('done testing')\n",
    "print('flickr')\n",
    "print(collections.Counter(wrd_idx_list_f30k))\n",
    "print(collections.Counter(sen_idx_list_f30k))\n",
    "print(cat_lvl_scores_f30k['clothing'][2])\n",
    "print('Cat_acc\\n', cat_iou_acc_f30k)\n",
    "print('Cat hit\\n', cat_hit_acc_f30k)\n",
    "print('Cat att\\n', cat_att_acc_f30k)\n",
    "print('iou_acc',iou_acc_f30k)\n",
    "print('hit_acc',hit_acc_f30k)\n",
    "print('att_acc',hit_acc_f30k)\n",
    "print('start saving')\n",
    "with open('./evaluations/train_pnas/test_f30k/'+condition+'.pickle', 'wb') as f:\n",
    "    pickle.dump({'iou_acc':iou_acc_f30k,\n",
    "                 'hit_acc':hit_acc_f30k,\n",
    "                 'att_acc':att_acc_f30k,\n",
    "                 'wrd_idx_list':wrd_idx_list_f30k,\n",
    "                 'sen_idx_list':sen_idx_list_f30k,\n",
    "                 'cat_lvl_scores':cat_lvl_scores_f30k,\n",
    "                 'cat_iou_acc':cat_iou_acc_f30k,\n",
    "                 'cat_hit_acc':cat_hit_acc_f30k,\n",
    "                 'cat_att_acc':cat_att_acc_f30k},f,protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print('done')\n",
    "\n",
    "\n",
    "print('Test on ReferIt\\n')\n",
    "#### ReferIt ####\n",
    "num_tst = len(dict_test_ref)\n",
    "iou_acc_ref_w, hit_acc_ref_w,att_acc_ref_w, iou_acc_ref_s, hit_acc_ref_s,att_acc_ref_s, wrd_idx_list_ref, sen_idx_list_ref = validate_referit_new(dict_test_ref,txn_ref)\n",
    "print('referit')\n",
    "print(collections.Counter(wrd_idx_list_ref))\n",
    "print(collections.Counter(sen_idx_list_ref))\n",
    "print('iou_acc_word',iou_acc_ref_w)\n",
    "print('iou_acc_sent',iou_acc_ref_s)\n",
    "print('hit_acc_word',hit_acc_ref_w)\n",
    "print('hit_acc_sent',hit_acc_ref_s)\n",
    "print('att_acc_sent',att_acc_ref_s)\n",
    "print('att_acc_word',att_acc_ref_w)\n",
    "\n",
    "with open('./evaluations/train_vg/test_referit/'+condition+'.pickle', 'wb') as f:\n",
    "    pickle.dump({'iou_acc_w':iou_acc_ref_w,\n",
    "                 'hit_acc_w':hit_acc_ref_w,\n",
    "                  'att_acc_w':att_acc_ref_w,\n",
    "                 'iou_acc_s':iou_acc_ref_s,\n",
    "                 'hit_acc_s':hit_acc_ref_s,\n",
    "                 'att_acc_s':att_acc_ref_s,\n",
    "                 'wrd_idx_list':wrd_idx_list_ref,\n",
    "                 'sen_idx_list':sen_idx_list_ref},f,protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print('All Done')\n",
    "\n",
    "print('Test on Visual Genome\\n')\n",
    "#### Visual Genome ####\n",
    "num_tst = len(dict_test_vg)\n",
    "iou_acc_vg_w, hit_acc_vg_w, att_acc_vg_w, iou_acc_vg_s, hit_acc_vg_s, att_acc_vg_s, wrd_idx_list_vg ,sen_idx_list_vg = validate_vg_new(dict_test_vg,txn_vg)\n",
    "print('All done.')\n",
    "print('visualgenome')\n",
    "print(collections.Counter(wrd_idx_list_vg))\n",
    "print(collections.Counter(sen_idx_list_vg))\n",
    "print('iou_acc_word',iou_acc_vg_w)\n",
    "print('iou_acc_sent',iou_acc_vg_s)\n",
    "print('hit_acc_word',hit_acc_vg_w)\n",
    "print('hit_acc_sent',hit_acc_vg_s)\n",
    "print('att_acc_sent',att_acc_vg_s)\n",
    "print('att_acc_word',att_acc_vg_w)\n",
    "with open('./evaluations/train_pnas/test_vg/'+condition+'.pickle', 'wb') as f:\n",
    "    pickle.dump({'iou_acc_w':iou_acc_vg_w,\n",
    "                 'hit_acc_w':hit_acc_vg_w,\n",
    "                  'att_acc_w':att_acc_vg_w,\n",
    "                 'iou_acc_s':iou_acc_vg_s,\n",
    "                 'hit_acc_s':hit_acc_vg_s,\n",
    "                 'att_acc_s':att_acc_vg_s,\n",
    "                 'wrd_idx_list':wrd_idx_list_vg,\n",
    "                 'sen_idx_list':sen_idx_list_vg},f,protocol=pickle.HIGHEST_PROTOCOL)\n",
    "print('AllDone')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def calc_idx(cat_lvl_scores,cats,method):\n",
    "#     cat_scr = {}\n",
    "#     cat_idx = {}\n",
    "#     cat_avg = {}\n",
    "#     n_lvl = 4\n",
    "#     final = [[' ']*(len(cats)+1) for _ in range((2*n_lvl))]\n",
    "#     final[0][0] = method\n",
    "#     for i,cat in enumerate(cats):\n",
    "#         cat_scr[cat]=[]\n",
    "#         cat_idx[cat]=[0]*n_lvl\n",
    "#         for scrs in cat_lvl_scores[cat]:\n",
    "#             cat_scr[cat].extend(scrs)\n",
    "#         tmp = np.argmax(cat_scr[cat],axis=1)\n",
    "#         for t in tmp:\n",
    "#             cat_idx[cat][t]+=1\n",
    "#         cat_avg[cat] = np.mean(cat_scr[cat],axis=0)\n",
    "#         for j in range(2*n_lvl):\n",
    "#             if j<n_lvl:\n",
    "#                 final[j][i+1] = cat_idx[cat][j]\n",
    "#             else:\n",
    "#                 final[j][i+1] = cat_avg[cat][j-n_lvl]\n",
    "#     return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#final = calc_idx(acc_dict['cat_lvl_scores'],m_rows_cat_idx[0][1:],e_f.split('/')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cat_n={}\n",
    "# for k_ in dict_test_f30k:\n",
    "#     for sen in dict_test_f30k[k_]['sentences']:\n",
    "#         for qry in dict_test_f30k[k_]['sentences'][sen]:\n",
    "#             for cat in dict_test_f30k[k_]['sentences'][sen][qry]['category']:\n",
    "#                 if cat=='notvisual':\n",
    "#                     continue\n",
    "#                 if cat not in cat_n:\n",
    "#                     cat_n[cat]=0\n",
    "#                 cat_n[cat]+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gather and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# cat_n={}\n",
    "# qry_n=0\n",
    "# for doc_id in dict_test_f30k:\n",
    "#     for sen in dict_test_f30k[doc_id]['sentences']:\n",
    "#         for query in dict_test_f30k[doc_id]['sentences'][sen]:\n",
    "#             idx = dict_test_f30k[doc_id]['sentences'][sen][query]['idx']\n",
    "#             if len(query.split())==0 or len(idx)==0:\n",
    "#                 continue\n",
    "#             annot = dict_test_f30k[doc_id]['sentences'][sen][query]\n",
    "#             category = annot['category']\n",
    "#             if 'notvisual' in category or len(annot['bbox_norm'])==0:\n",
    "#                 continue\n",
    "#             if not check_percent(union(annot['bbox_norm'])):\n",
    "#                 continue\n",
    "                    \n",
    "#             for cat in category:\n",
    "#                 if cat=='notvisual':\n",
    "#                     continue\n",
    "#                 if cat not in cat_n:\n",
    "#                     cat_n[cat]=0\n",
    "#                 cat_n[cat]+=1\n",
    "#                 qry_n+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print(qry_n)\n",
    "# cat_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def calc_idx(cat_lvl_scores,cats,method):\n",
    "#     cat_scr = {}\n",
    "#     cat_idx = {}\n",
    "#     cat_avg = {}\n",
    "#     n_lvl = 4\n",
    "#     final = [[' ']*(len(cats)+1) for _ in range((2*n_lvl))]\n",
    "#     final[0][0] = method\n",
    "#     for i,cat in enumerate(cats):\n",
    "#         cat_scr[cat]=[]\n",
    "#         cat_idx[cat]=[0]*n_lvl\n",
    "#         for scrs in cat_lvl_scores[cat]:\n",
    "#             cat_scr[cat].extend(scrs)\n",
    "#         tmp = np.argmax(cat_scr[cat],axis=1)\n",
    "#         for t in tmp:\n",
    "#             cat_idx[cat][t]+=1\n",
    "#         cat_avg[cat] = np.mean(cat_scr[cat],axis=0)\n",
    "#         for j in range(2*n_lvl):\n",
    "#             if j<n_lvl:\n",
    "#                 final[j][i+1] = cat_idx[cat][j]\n",
    "#             else:\n",
    "#                 final[j][i+1] = cat_avg[cat][j-n_lvl]\n",
    "#     return final\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import collections\n",
    "train = ['vg','pnas']\n",
    "test = ['f30k','referit','vg']\n",
    "#test = ['f30k']\n",
    "pre_path = './evaluations/train_'\n",
    "cols = ['iou_acc_w','iou_acc_s','hit_acc_w','hit_acc_s','att_acc_w','att_acc_s','Layer0_Word','Layer1_Word',\\\n",
    "                    'Layer2_Word','Layer3_Word','Layer0_Sen','Layer1_Sen', 'Layer2_Sen','Layer3_Sen']\n",
    "df = pd.DataFrame(columns = cols)\n",
    "tmp_cols = ['iou_acc','iou_acc','hit_acc','hit_acc','att_acc','att_acc']\n",
    "names =[]\n",
    "counter = 0\n",
    "for train_ in train:\n",
    "    print(train_)\n",
    "    for test_ in test:\n",
    "        print(test_ + 'started')\n",
    "        dir_path = pre_path + train_ + '/test_' + test_+ '/*pickle'\n",
    "        files = glob.glob(dir_path)\n",
    "        #print(files)\n",
    "        ####print(files)\n",
    "        for f in files:\n",
    "            file = open(f,'rb')\n",
    "            data = pickle.load(file)\n",
    "            \n",
    "            name = train_ + test_+ ' '+ f.split('/')[-1].split('_')[-2] + f.split('/')[-1].split('_')[-1]\n",
    "            name = name.split('.')[0]\n",
    "            #print(name)\n",
    "            names.append(name)\n",
    "            stats = []\n",
    "            #stats.append(name)\n",
    "            wrd_counter = collections.Counter(data['wrd_idx_list'])\n",
    "            sen_counter = collections.Counter(data['sen_idx_list'])\n",
    "            \n",
    "            if test_=='f30k':\n",
    "                #print(tmp_cols)\n",
    "                #print(data)\n",
    "                for x in tmp_cols[0:6]: \n",
    "                    if x in data:\n",
    "                        stats.append(round(data[x]*100,2))\n",
    "                    else:\n",
    "                        stats.append(0)\n",
    "            else:\n",
    "                for x in cols[0:6]:\n",
    "                    if x in data:\n",
    "                        stats.append(round(data[x]*100,2))\n",
    "                    else:\n",
    "                        stats.append(0)\n",
    "                    \n",
    "            for i in range(0,4):\n",
    "                if i in wrd_counter:\n",
    "                    stats.append(wrd_counter[i])\n",
    "                else:\n",
    "                    stats.append(0)\n",
    "            for i in range(0,4):\n",
    "                if i in sen_counter:\n",
    "                    stats.append(int(sen_counter[i]))\n",
    "                else:\n",
    "                    stats.append(int(0))\n",
    "            df.loc[counter] = stats\n",
    "            counter += 1\n",
    "\n",
    "df.index = names\n",
    "df['name'] = names\n",
    "df  \n",
    "df.to_csv('SummaryVGTrain.csv')\n",
    "df\n",
    "# for nlayer1 accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# m_rows\n",
    "# m_rows_cat_hit\n",
    "# m_rows_cat_att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# myFile = open('./evaluations/cat_wise_lvl_idx.csv', 'w')  \n",
    "# with myFile:\n",
    "#     writer = csv.writer(myFile)\n",
    "#     writer.writerows(m_rows_cat_idx)\n",
    "    \n",
    "# myFile = open('./evaluations/cat_wise_hit.csv', 'w')  \n",
    "# with myFile:\n",
    "#     writer = csv.writer(myFile)\n",
    "#     writer.writerows(m_rows_cat_hit)\n",
    "    \n",
    "# myFile = open('./evaluations/cat_wise_att.csv', 'w')  \n",
    "# with myFile:\n",
    "#     writer = csv.writer(myFile)\n",
    "#     writer.writerows(m_rows_cat_att)\n",
    "    \n",
    "# myFile = open('./evaluations/overall.csv', 'w')  \n",
    "# with myFile:\n",
    "#     writer = csv.writer(myFile)\n",
    "#     writer.writerows(m_rows_l)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#mention level\n",
    "from textwrap import wrap\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from utils import img_heat_bbox_disp\n",
    "\n",
    "pdf = PdfPages(\"VGG_Depth_VG_on_Flickr30k_Level.pdf\")\n",
    "for k,doc_id in enumerate(dict_test):\n",
    "    prnt = 'Sample {}/{} \\r'.format(k,len(dict_test))\n",
    "    sys.stdout.write(prnt)                \n",
    "    sys.stdout.flush()\n",
    "    img = np.reshape(cv2.resize(dict_test[doc_id]['img'],(299,299)),(1,299,299,3))\n",
    "    orig_img_shape = dict_test[doc_id]['size']\n",
    "    sen_batch = list(dict_test[doc_id]['sentences'].keys())\n",
    "    img_batch = np.repeat(img,len(sen_batch),axis=0)\n",
    "    tensor_list = [heatmap_w, heatmap_s, R_i, R_s, lvl_idx_wrd, lvl_idx_sen]\n",
    "    feed_dict = {input_img: img_batch, text_batch: sen_batch, mode: 'test'}\n",
    "    qry_heats, sen_heat, qry_scores, sen_score, w_idx, sen_idx = sess.run(tensor_list, feed_dict)\n",
    "    for c,sen in enumerate(sen_batch):\n",
    "        if c>0:\n",
    "            continue\n",
    "        title_str = sen#+',  Sen-Img Score: %.2f'%sen_score\n",
    "        title = \"\\n\".join(wrap(title_str, 120))\n",
    "        heatmap = sen_heat[c]\n",
    "        fig = img_heat_bbox_disp(img[0,:], heatmap, title=title, en_name=None, bboxes=[], order='xyxy',show=False,dot_max=True)\n",
    "        pdf.savefig(fig)\n",
    "        for query in dict_test[doc_id]['sentences'][sen]:\n",
    "            #reject not groundable/acceptable queries\n",
    "            idx = dict_test[doc_id]['sentences'][sen][query]['idx']\n",
    "            if len(query.split())==0 or len(idx)==0:\n",
    "                continue\n",
    "            annot = dict_test[doc_id]['sentences'][sen][query]\n",
    "            category = annot['category']\n",
    "            if 'notvisual' in category or len(annot['bbox_norm'])==0:\n",
    "                continue\n",
    "            if not check_percent(union(annot['bbox_norm'])):\n",
    "                continue\n",
    "            #if reaches this point, it is groundable/acceptable\n",
    "\n",
    "            if np.mean(qry_scores[c,idx])==0:\n",
    "                continue\n",
    "            else:\n",
    "                heatmap = np.average(qry_heats[c,idx,:], weights = qry_scores[c,idx], axis=0)\n",
    "                strs_idx = [str(s) for s in w_idx[c,idx]]\n",
    "                en_txt = query+', %.2f'%np.mean(qry_scores[c,idx])+', '+','.join(strs_idx)\n",
    "                fig = img_heat_bbox_disp(img[0,:], heatmap, title=title, en_name=en_txt, bboxes=annot['bbox_norm'], order='xyxy', show=False,dot_max=True)\n",
    "                pdf.savefig(fig)\n",
    "pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pdf.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_tst = len(dict_test)\n",
    "iou_acc_f,hit_acc_f = validate_flickr30k(dict_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Level Histogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#VGG on VG\n",
    "plt.hist(idx_wrd, bins=10)\n",
    "plt.hist(idx_sen, bins=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#VGG on MSCOCO\n",
    "plt.hist(idx_wrd, bins=10)\n",
    "plt.hist(idx_sen, bins=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#PNASNET on VG\n",
    "plt.hist(idx_wrd, bins=10)\n",
    "plt.hist(idx_sen, bins=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = []\n",
    "idx_wrd = []\n",
    "idx_sen = []\n",
    "idx_wrd_tf = sess.graph.get_tensor_by_name('attention/ArgMax:0')\n",
    "idx_sen_tf = sess.graph.get_tensor_by_name('attention/ArgMax_1:0')\n",
    "for k,doc_id in enumerate(dict_test):\n",
    "    prnt = 'Sample {}/{} \\r'.format(k,len(dict_test))\n",
    "    sys.stdout.write(prnt)                \n",
    "    sys.stdout.flush()\n",
    "    img = np.reshape(cv2.resize(dict_test[doc_id]['img'],(299,299)),(1,299,299,3))\n",
    "    orig_img_shape = dict_test[doc_id]['size']\n",
    "    sen_batch = list(dict_test[doc_id]['sentences'].keys())\n",
    "    img_batch = np.repeat(img,len(sen_batch),axis=0)\n",
    "    tensor_list = [idx_wrd_tf, idx_sen_tf]\n",
    "    feed_dict = {input_img: img_batch, text_batch: sen_batch, mode: 'test'}\n",
    "    idx_max_w, idx_max_s = sess.run(tensor_list, feed_dict)\n",
    "    idx_sen.extend(idx_max_s)\n",
    "    for c,sen in enumerate(sen_batch):\n",
    "        wrds = sen.split()\n",
    "        words.extend(wrds)\n",
    "        idx_wrd.extend(idx_max_w[c,:len(wrds)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!tensorboard --logdir ../logs/vgg/vg --port=8993"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
